{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesesary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"NVIDIA_API_KEY\"]=os.getenv('NVIDIA_API_KEY')\n",
    "os.environ['LANGSMITH_API_KEY']=os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_TRACING']=os.getenv('LANGSMITH_TRACING')\n",
    "os.environ['LANGSMITH_PROJECT']=os.getenv('LANGSMITH_PROJECT',\"Your-proejct-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('../langchain_crawl_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_urls = (df[df['Type']=='page'].URL).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loader = UnstructuredURLLoader(list_of_urls[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader(list_of_urls[:10])\n",
    "\n",
    "web_docs = web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Markdown(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "spliter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=100)\n",
    "documents = spliter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "# nvidia/nv-embedcode-7b-v1 ---> Mistralbased code optimized\n",
    "# nvidia/llama-3.2-nv-embedqa-1b-v2 ---> Llama based QA optimized\n",
    "embeddings_model = NVIDIAEmbeddings(\n",
    "    model=\"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n",
    "    api_key=os.getenv(\"NVIDIA_API_KEY\"),\n",
    "    truncate=\"NONE\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectore_store = FAISS.from_documents(documents, embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_result = vectore_store.similarity_search(\"What is the purpose of the langchain\")\n",
    "display.Markdown(similar_result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt= ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the user follwing qestin based on only on the provided contet:\n",
    "\n",
    "    {context}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_client = ChatNVIDIA(\n",
    "    model=\"deepseek-ai/deepseek-r1-distill-llama-8b\",\n",
    "    api_key=os.getenv('NVIDIA_API_KEY'),\n",
    "    temperature=0.6,\n",
    "    top_p=0.7,\n",
    "    max_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain= create_stuff_documents_chain(\n",
    "    llm_client, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "retriver = vectore_store.as_retriever()\n",
    "retrival_chain = create_retrieval_chain(retriver, document_chain)\n",
    "retrival_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsonse = retrival_chain.invoke({\"input\":\"give me a list of All chat models available\"})\n",
    "display.Markdown(repsonse['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for chunk in retrival_chain.stream({\n",
    "        \"input\": \"What is the langchain project all about?\"\n",
    "    }):\n",
    "        if 'answer' in chunk:\n",
    "            print(chunk['answer'], end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store.save_local(\"langchain_faiss_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
